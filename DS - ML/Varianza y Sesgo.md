
## Sesgo

Cuando el modelo no ajusta bien al conjunto de entrenamiento. Por ejemplo una regresión lineal en un conjunto de entrenamiento que ajustaria mejor con una polimonial. Tiene un sesgo alto.

## Varianza

En este caso, un modelo polimionial alto, ajusta muy bien al entrenamiento por lo que tiene poco sesgo pero alta varianza.
Si se comporta bien en training y mal en testing, tiene una varianza alta.


El modelo óptimo es un modelo compensado entre la varianza y el sesgo.


## Regularización L2

Es para evitar el sobreajuste.

El modelo introduce un término de error para que no funcione tan bien en el entrenamiento y mejor en el de testing.


## Regularización L1

Es similar a la L2.